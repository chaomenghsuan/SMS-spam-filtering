{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import itertools as it\n",
    "import nltk\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data processing: extract data from .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms = pd.read_csv('/Users/zhaomengxuan/Documents/text mining/final project/spam.csv', encoding='latin-1')\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop column and name change\n",
    "sms = sms.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "sms = sms.rename(columns={\"v1\":\"label\", \"v2\":\"text\"})\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count observations in each label\n",
    "sms.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data processing: extract structural features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       " 'Ok lar... Joking wif u oni...',\n",
       " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       " 'U dun say so early hor... U c already then say...',\n",
       " \"Nah I don't think he goes to usf, he lives around here though\"]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawtext = [sms['text'][n] for n in range(len(sms))]\n",
    "rawtext[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[111, 29, 155, 49, 61]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# structural feature 1: sms message length\n",
    "sms_length = [len(st) for st in rawtext]\n",
    "sms_length[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.16129032258064516, 0.0, 0.0]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# structural feature 2: numeric character ratio\n",
    "numeric = [len(re.findall(r'\\d', rawtext[i]))/len(rawtext[i]) for i in range(len(rawtext))]\n",
    "numeric[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08108108108108109,\n",
       " 0.20689655172413793,\n",
       " 0.03870967741935484,\n",
       " 0.12244897959183673,\n",
       " 0.03278688524590164]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# structural features 3: non-alphanumeric character ratio\n",
    "non_alphanumeric_pt = re.compile(r'[^\\w\\s]+')\n",
    "non_alphanumeric = [len(''.join(re.findall(non_alphanumeric_pt, rawtext[i])))/len(rawtext[i]) for i in range(len(rawtext))]\n",
    "non_alphanumeric[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15,\n",
       " 304,\n",
       " 517,\n",
       " 634,\n",
       " 832,\n",
       " 880,\n",
       " 1104,\n",
       " 3057,\n",
       " 3172,\n",
       " 3461,\n",
       " 3461,\n",
       " 3860,\n",
       " 3883,\n",
       " 4164,\n",
       " 4204,\n",
       " 4256,\n",
       " 4278,\n",
       " 4353,\n",
       " 4963]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# structural feature 4: if sms message include url\n",
    "# include: 1, non: 0\n",
    "url_index = [rawtext.index(st) for st in rawtext if 'http://' in st]\n",
    "url_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = [0] * len(rawtext)\n",
    "for i in url_index:\n",
    "    url[i] += 1\n",
    "url[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat',\n",
       " 'Ok lar Joking wif u oni',\n",
       " 'Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive entry questionstd txt rateTCs apply 08452810075over18s',\n",
       " 'U dun say so early hor U c already then say',\n",
       " 'Nah I dont think he goes to usf he lives around here though']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [sent.translate(str.maketrans('', '', string.punctuation)) for sent in rawtext]\n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go until jurong point crazy Available only in bugis n great world la e buffet Cine there got amore wat',\n",
       " 'Ok lar Joking wif u oni',\n",
       " 'Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive entry questionstd txt rateTCs apply 08452810075over18s',\n",
       " 'U dun say so early hor U c already then say',\n",
       " 'Nah I dont think he goes to usf he lives around here though',\n",
       " 'FreeMsg Hey there darling its been 3 weeks now and no word back Id like some fun you up for it still Tb ok XxX std chgs to send å£150 to rcv',\n",
       " 'Even my brother is not like to speak with me They treat me like aids patent',\n",
       " 'As per your request Melle Melle Oru Minnaminunginte Nurungu Vettam has been set as your callertune for all Callers Press 9 to copy your friends Callertune',\n",
       " 'WINNER As a valued network customer you have been selected to receivea å£900 prize reward To claim call <longdigit> Claim code KL341 Valid 12 hours only',\n",
       " 'Had your mobile 11 months or more U R entitled to Update to the latest colour mobiles with camera for Free Call The Mobile Update Co FREE on <longdigit>']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = re.compile(r'\\b\\d{10,}\\b')\n",
    "text = [re.sub(digits, '<longdigit>', sent) for sent in text]\n",
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.029411764705882353,\n",
       " 0.08695652173913043,\n",
       " 0.06711409395973154,\n",
       " 0.046511627906976744,\n",
       " 0.03389830508474576]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# structural feature 5: uppercase charactor ratio\n",
    "def countupper(string):\n",
    "    n = 0\n",
    "    for letter in string:\n",
    "        if letter.isupper(): n += 1\n",
    "    ratio = n/len(string)\n",
    "    return ratio\n",
    "upper = [countupper(st) for st in text]\n",
    "upper[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['go',\n",
       "  'until',\n",
       "  'jurong',\n",
       "  'point',\n",
       "  'crazy',\n",
       "  'available',\n",
       "  'only',\n",
       "  'in',\n",
       "  'bugis',\n",
       "  'n',\n",
       "  'great',\n",
       "  'world',\n",
       "  'la',\n",
       "  'e',\n",
       "  'buffet',\n",
       "  'cine',\n",
       "  'there',\n",
       "  'got',\n",
       "  'amore',\n",
       "  'wat'],\n",
       " ['ok', 'lar', 'joking', 'wif', 'u', 'oni'],\n",
       " ['free',\n",
       "  'entry',\n",
       "  'in',\n",
       "  '2',\n",
       "  'a',\n",
       "  'wkly',\n",
       "  'comp',\n",
       "  'to',\n",
       "  'win',\n",
       "  'fa',\n",
       "  'cup',\n",
       "  'final',\n",
       "  'tkts',\n",
       "  '21st',\n",
       "  'may',\n",
       "  '2005',\n",
       "  'text',\n",
       "  'fa',\n",
       "  'to',\n",
       "  '87121',\n",
       "  'to',\n",
       "  'receive',\n",
       "  'entry',\n",
       "  'questionstd',\n",
       "  'txt',\n",
       "  'ratetcs',\n",
       "  'apply',\n",
       "  '08452810075over18s'],\n",
       " ['u', 'dun', 'say', 'so', 'early', 'hor', 'u', 'c', 'already', 'then', 'say'],\n",
       " ['nah',\n",
       "  'i',\n",
       "  'dont',\n",
       "  'think',\n",
       "  'he',\n",
       "  'goes',\n",
       "  'to',\n",
       "  'usf',\n",
       "  'he',\n",
       "  'lives',\n",
       "  'around',\n",
       "  'here',\n",
       "  'though']]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lower = [[w.lower() for w in sent.split()] for sent in text]\n",
    "text_lower[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 6, 28, 11, 13]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# structural reature 6: number of terms\n",
    "terms_count = [len(t) for t in text_lower]\n",
    "terms_count[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 6)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structural = np.matrix(np.array([sms_length, numeric, non_alphanumeric, url, upper, terms_count])).T\n",
    "structural.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training (70%), dev (10%)(used later for neural net model) and testing (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr = int(len(text_lower)*0.7)\n",
    "dev = int(len(text_lower)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_train, text_dev, text_test = text_lower[:tr], text_lower[tr:dev], text_lower[dev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_train, text_test, text_dev = \\\n",
    "[' '.join(sent) for sent in text_train],\\\n",
    "[' '.join(sent) for sent in text_test],\\\n",
    "[' '.join(sent) for sent in text_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "vec.fit(text_train)\n",
    "Xtrain, Xtest, Xdev = vec.transform(text_train), \\\n",
    "vec.transform(text_test), vec.transform(text_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Xdev = \\\n",
    "csr_matrix(Xtrain).toarray(), csr_matrix(Xtest).toarray(), csr_matrix(Xdev).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 7600)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structural_train, structural_dev, structural_test = \\\n",
    "structural[:tr], structural[tr:dev], structural[dev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr, Xte, Xdev = \\\n",
    "np.concatenate((Xtrain.T, structural_train.T)).T, \\\n",
    "np.concatenate((Xtest.T, structural_test.T)).T, \\\n",
    "np.concatenate((Xdev.T, structural_dev.T)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 7606)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115, 7606)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xte.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557, 7606)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels for NB/SVM: 0 for non-spam, 1 for spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplelabels = []\n",
    "for i in range(len(sms)):\n",
    "    if sms['label'][i] == 'ham':\n",
    "        simplelabels.append(0)\n",
    "    elif sms['label'][i] == 'spam':\n",
    "        simplelabels.append(1)\n",
    "simplelabels = np.array(simplelabels)\n",
    "simplelabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels for tensorflow: [0,1] for non-spam, [1,0] for spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(sms)):\n",
    "    if sms['label'][i] == 'ham':\n",
    "        labels.append([1,0])\n",
    "    elif sms['label'][i] == 'spam':\n",
    "        labels.append([0,1])\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No. of Spam vs Ham in Each Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     3381\n",
       "spam     519\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set\n",
    "# 3381 non-spam, 519 spam, 6.5:1\n",
    "sms.label[:tr].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     474\n",
       "spam     83\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# development set\n",
    "# used later\n",
    "sms.label[tr:dev].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     970\n",
       "spam    145\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing set\n",
    "# 970 non-spam, 145 spam, 6.7:1\n",
    "sms.label[dev:].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels for NB, K-NN, SVM\n",
    "# no dev set\n",
    "simpytr, simpyte = simplelabels[:tr], simplelabels[dev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115,)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpyte.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels for neural net\n",
    "# training 70%, dev 10%, testing 20%\n",
    "ytr, ydev, yte = labels[:tr], labels[tr:dev], labels[dev:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(Xtr, simpytr)\n",
    "pred_nb = clf_nb.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precission: 0.962\n",
      "Recall: 0.862\n",
      "F1 Score: 0.909\n"
     ]
    }
   ],
   "source": [
    "print('Precission:', round(sklearn.metrics.precision_score(simpyte, pred_nb), 3))\n",
    "print('Recall:', round(sklearn.metrics.recall_score(simpyte, pred_nb), 3))\n",
    "print('F1 Score:', round(sklearn.metrics.f1_score(simpyte, pred_nb), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict non-spam</th>\n",
       "      <th>predict spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-spam</th>\n",
       "      <td>965</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>20</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predict non-spam  predict spam\n",
       "non-spam               965             5\n",
       "spam                    20           125"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sklearn.metrics.confusion_matrix(simpyte, pred_nb), index=['non-spam', 'spam'], \n",
    "             columns=['predict non-spam','predict spam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "clf_knn.fit(Xtr, simpytr)\n",
    "pred_knn = clf_knn.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_knn[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precission: 0.768\n",
      "Recall: 0.89\n",
      "F1 Score: 0.824\n"
     ]
    }
   ],
   "source": [
    "print('Precission:', round(sklearn.metrics.precision_score(simpyte, pred_knn), 3))\n",
    "print('Recall:', round(sklearn.metrics.recall_score(simpyte, pred_knn), 3))\n",
    "print('F1 Score:', round(sklearn.metrics.f1_score(simpyte, pred_knn), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict non-spam</th>\n",
       "      <th>predict spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-spam</th>\n",
       "      <td>931</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>16</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predict non-spam  predict spam\n",
       "non-spam               931            39\n",
       "spam                    16           129"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sklearn.metrics.confusion_matrix(simpyte, pred_knn), index=['non-spam', 'spam'], \n",
    "             columns=['predict non-spam','predict spam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_svm = svm.SVC(kernel='linear')\n",
    "clf_svm.fit(Xtr, simpytr)\n",
    "pred_svm = clf_svm.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_svm[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precission: 0.964\n",
      "Recall: 0.91\n",
      "F1 Score: 0.936\n"
     ]
    }
   ],
   "source": [
    "print('Precission:', round(sklearn.metrics.precision_score(simpyte, pred_svm), 3))\n",
    "print('Recall:', round(sklearn.metrics.recall_score(simpyte, pred_svm), 3))\n",
    "print('F1 Score:', round(sklearn.metrics.f1_score(simpyte, pred_svm), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict non-spam</th>\n",
       "      <th>predict spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-spam</th>\n",
       "      <td>965</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>13</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predict non-spam  predict spam\n",
       "non-spam               965             5\n",
       "spam                    13           132"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sklearn.metrics.confusion_matrix(simpyte, pred_svm), index=['non-spam', 'spam'], \n",
    "             columns=['predict non-spam','predict spam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi-layer Perceptron Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_input = Xtr.shape[1]\n",
    "num_classes = ytr.shape[1]\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1 = 8\n",
    "n_hidden_2 = 8\n",
    "n_hidden_3 = 8\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_3, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def neural_net(x):\n",
    "    # Hidden fully connected layer with 500 neurons\n",
    "    layer_1 = tf.nn.sigmoid((tf.add(tf.matmul(x, weights['h1']), biases['b1'])))\n",
    "    # Hidden fully connected layer with 500 neurons\n",
    "    layer_2 = tf.nn.sigmoid((tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])))\n",
    "    # Hidden fully connected layer with 500 neurons\n",
    "    layer_3 = tf.nn.sigmoid((tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])))\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.nn.sigmoid((tf.matmul(layer_3, weights['out']) + biases['out']))\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "num_steps = 300\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "logits = neural_net(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.nn.l2_loss(logits - Y)\n",
    "optimizer = tf.train.FtrlOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, L2 Loss= 504.036, Training Accuracy= 0.867\n",
      "Step 50, L2 Loss= 406.182, Training Accuracy= 0.867\n",
      "Step 100, L2 Loss= 42.810, Training Accuracy= 0.995\n",
      "Step 150, L2 Loss= 18.045, Training Accuracy= 0.998\n",
      "Step 200, L2 Loss= 13.059, Training Accuracy= 0.998\n",
      "Step 250, L2 Loss= 11.456, Training Accuracy= 0.998\n",
      "Step 300, L2 Loss= 10.593, Training Accuracy= 0.998\n",
      "Optimization Finished!\n",
      "\n",
      "Development set results:\n",
      "precision: 0.961\n",
      "recall: 0.88\n",
      "F1 score: 0.918\n",
      "          predict non-spam  predict spam\n",
      "non-spam               471             3\n",
      "spam                    10            73\n",
      "\n",
      "Testing set results:\n",
      "precision: 0.97\n",
      "recall: 0.897\n",
      "F1 score: 0.932\n",
      "          predict non-spam  predict spam\n",
      "non-spam               966             4\n",
      "spam                    15           130\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: Xtr, Y: ytr})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: Xtr,\n",
    "                                                                 Y: ytr})\n",
    "            print(\"Step \" + str(step) + \", L2 Loss= \" + \\\n",
    "                  \"{:.3f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # calculate precision, recall and f1 score on dev set, using sklearn\n",
    "    pred_label = sess.run(logits, feed_dict={X: Xdev})\n",
    "    pred = sess.run(tf.argmax(pred_label,1))\n",
    "    y = sess.run(tf.argmax(ydev,1))\n",
    "    \n",
    "    print('\\nDevelopment set results:')\n",
    "    print('precision:', round(sklearn.metrics.precision_score(y, pred),3))\n",
    "    print('recall:', round(sklearn.metrics.recall_score(y, pred),3))\n",
    "    print('F1 score:',round(sklearn.metrics.f1_score(y, pred),3))\n",
    "    print(pd.DataFrame(sklearn.metrics.confusion_matrix(y, pred), index=['non-spam', 'spam'], \n",
    "             columns=['predict non-spam','predict spam']))\n",
    "    \n",
    "    # calculate precision, recall and f1 score on testing set \n",
    "    pred_label_te = sess.run(logits, feed_dict={X: Xte})\n",
    "    pred_te = sess.run(tf.argmax(pred_label_te,1))\n",
    "    y_te = sess.run(tf.argmax(yte,1))\n",
    "    \n",
    "    print('\\nTesting set results:')\n",
    "    print('precision:', round(sklearn.metrics.precision_score(y_te, pred_te),3))\n",
    "    print('recall:', round(sklearn.metrics.recall_score(y_te, pred_te),3))\n",
    "    print('F1 score:',round(sklearn.metrics.f1_score(y_te, pred_te),3))\n",
    "    print(pd.DataFrame(sklearn.metrics.confusion_matrix(y_te, pred_te), index=['non-spam', 'spam'], \n",
    "             columns=['predict non-spam','predict spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
